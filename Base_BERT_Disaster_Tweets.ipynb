{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X-OlE5oOw9E5","executionInfo":{"status":"ok","timestamp":1652657811548,"user_tz":240,"elapsed":11914,"user":{"displayName":"SYED NAWSHAD","userId":"11649352150405688224"}},"outputId":"4547fdb1-600e-40de-c610-6801135e8cb7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (2.2.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n","Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.3.0)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n","Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.18.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.6.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.11.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.25.11)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.7.2)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.12)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.0)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.19.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.6.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n"]}],"source":["!pip install datasets\n","!pip install transformers"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ftmxzqZfCzW0","executionInfo":{"status":"ok","timestamp":1652657812409,"user_tz":240,"elapsed":867,"user":{"displayName":"SYED NAWSHAD","userId":"11649352150405688224"}},"outputId":"fd4c19bd-8cf8-42cf-fceb-cabff8a821fe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import torch\n","from torch import cuda\n","import random\n","import os\n","import torch\n","from torch import nn\n","from transformers import Trainer\n","from collections import Counter\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import f1_score, classification_report\n","from sklearn.utils.class_weight import compute_class_weight\n","import datasets\n","from datasets import Dataset, load_metric\n","import transformers\n","from transformers import AutoTokenizer\n","from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding\n","\n","print(torch.__version__)\n","print(transformers.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AtjVYxsx0VCF","executionInfo":{"status":"ok","timestamp":1652657812410,"user_tz":240,"elapsed":10,"user":{"displayName":"SYED NAWSHAD","userId":"11649352150405688224"}},"outputId":"592d0f9c-f5c4-43ce-ccd8-5e1142ef6197"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1.11.0+cu113\n","4.19.1\n"]}]},{"cell_type":"code","source":["cd /content/drive/MyDrive/Colab Notebooks"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MG17VnLl1Fv6","executionInfo":{"status":"ok","timestamp":1652657812410,"user_tz":240,"elapsed":8,"user":{"displayName":"SYED NAWSHAD","userId":"11649352150405688224"}},"outputId":"e6c3d0ee-7387-4392-8b6e-d2b339933acb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aOrPHSOSw9E-"},"outputs":[],"source":["train_path = './nlp-getting-started/train.csv'\n","train_data = pd.read_csv(train_path)\n","train_data = train_data[['text', 'target']]\n","train_data.rename(columns={\"target\": \"label\"}, inplace=True)\n","\n","test_path = './nlp-getting-started/train.csv'\n","test_data = pd.read_csv(test_path)\n","test_data = test_data[['text']]\n","test_data.rename(columns={\"target\": \"label\"}, inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Sbre0GsJw9E-","executionInfo":{"status":"ok","timestamp":1652657812411,"user_tz":240,"elapsed":6,"user":{"displayName":"SYED NAWSHAD","userId":"11649352150405688224"}},"outputId":"1996fbbc-259a-4096-cc64-22f5d3735a5e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train dataset labels count =  Counter({0: 3907, 1: 2944})\n","Dev dataset labels count =  Counter({0: 435, 1: 327})\n"]}],"source":["train_data, dev_data = train_test_split(train_data, test_size=0.1, shuffle=True, stratify=train_data['label'])\n","\n","print(\"Train dataset labels count = \", Counter(train_data['label']))\n","print(\"Dev dataset labels count = \", Counter(dev_data['label']))\n","#print(\"Test dataset labels count = \", Counter(test_data['target'])) #test dataset does not contain the target label"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"md42cgLZw9E_","executionInfo":{"status":"ok","timestamp":1652657817784,"user_tz":240,"elapsed":5378,"user":{"displayName":"SYED NAWSHAD","userId":"11649352150405688224"}},"outputId":"7e7e55fc-e8f1-4500-e093-95e80a36434b"},"outputs":[{"output_type":"stream","name":"stderr","text":["loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n","Model config BertConfig {\n","  \"_name_or_path\": \"bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.19.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n","loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n","loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n","loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n","Model config BertConfig {\n","  \"_name_or_path\": \"bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.19.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n","Model config BertConfig {\n","  \"_name_or_path\": \"bert-base-uncased\",\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.19.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n","loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["model_checkpoint = 'bert-base-uncased'\n","tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=False)\n","model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=2).to('cuda')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5IpN56kxw9E_"},"outputs":[],"source":["def preprocess_function(examples):\n","    return tokenizer(examples['text'], truncation=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["1a3a7468d9f04a9e82a6f186d7d0d58b","3a222dc384b8448ca27c005bd8f99885","9387fb917e2d4feab271f00a6ff26f84","7dd8d34f006c480cb2f5eb199a6b3c7c","459542131e09425ea904822aa676a24d","7e16e4956e524cad8e16c2c0131d91bd","9af89e4f8bb1483e88952aec7a15522c","d3383134371c491b85f99c3c740b3485","07d139fad4d342ed8e34ef48ff832784","deef14893fcc47ef9d77772de4c9e687","69730dde435840f1af4edee14e309cfa","681d960626c04e9a8bd5e994ed44e983","dae9098bd2e6428987b136b3d7065d9d","c8247213072b4ed0854285a538c40633","dde67639c1c4476da066996a1e4c7d34","1ac02a881d5947ca942aa1156b3f907c","8ccc25e972c34e90b5e5e6d63a20048e","5d2b4aa2cc69481887f2b12a0dfd8c76","f08a4b01eac44999a0fb3ef40bea4982","52fd5a1be15d4af79945c1ca21746e02","14252d3e485446a288b5f76943c45765","e28340c964a6489f8889f54d924d9fe4","45d96734b8f94c8eacaad0fbfac5851b","07a7259ac87c4d44905926c2846fb8c6","3a2d94b24a0e40aa8cdf5c69c852d7bd","6beebd44d1924e659b5a3258030715a2","b9a3a7bd2b734ff4b6dfc631eb1a2f00","23c3345255e740d6a3f3d8ca3bcbc5e6","95cb2825257d43b9a912c99288a2e4e9","faf7316f012a4ca981ab3bb4a026c03a","f8ca15121cea41a2917e236b1da9b597","5bd09b60d88a4e2bba9c4c0f03ffd4eb","09758a28cab34b9786de78b888b080e7"]},"id":"5l2F7WYiw9FA","executionInfo":{"status":"ok","timestamp":1652657836651,"user_tz":240,"elapsed":18870,"user":{"displayName":"SYED NAWSHAD","userId":"11649352150405688224"}},"outputId":"1425a127-c611-4cd9-f556-e64a6d2df316"},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/7 [00:00<?, ?ba/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a3a7468d9f04a9e82a6f186d7d0d58b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"681d960626c04e9a8bd5e994ed44e983"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/8 [00:00<?, ?ba/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"45d96734b8f94c8eacaad0fbfac5851b"}},"metadata":{}}],"source":["train_data = Dataset.from_pandas(train_data)\n","dev_data = Dataset.from_pandas(dev_data)\n","test_data = Dataset.from_pandas(test_data)\n","\n","encoded_dataset_train = train_data.map(preprocess_function, batched=True)\n","encoded_dataset_dev = dev_data.map(preprocess_function, batched=True)\n","encoded_dataset_test = test_data.map(preprocess_function, batched=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BarYTTU7w9FA"},"outputs":[],"source":["columns_to_return = ['input_ids', 'label', 'attention_mask']\n","columns_to_return_test = ['input_ids', 'attention_mask']\n","encoded_dataset_train.set_format(columns=columns_to_return)\n","encoded_dataset_dev.set_format(columns=columns_to_return)\n","encoded_dataset_test.set_format(columns=columns_to_return_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QMVMTSHhw9FB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652657836653,"user_tz":240,"elapsed":6,"user":{"displayName":"SYED NAWSHAD","userId":"11649352150405688224"}},"outputId":"bf55c8d0-66a0-4495-c061-66a7af5437f3"},"outputs":[{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"]}],"source":["batch_size = 8\n","metric_name = \"f1\"\n","model_name = model_checkpoint.split(\"/\")[-1]\n","task = 'tweet'\n","\n","args = TrainingArguments(\n","    f\"./save_model/{model_name}-finetuned-{task}\",\n","    evaluation_strategy = \"epoch\",\n","    save_strategy = \"epoch\",\n","    learning_rate=1e-5,\n","    per_device_train_batch_size=batch_size,\n","    per_device_eval_batch_size=batch_size,\n","    num_train_epochs=4,\n","    weight_decay=0.01,\n","    load_best_model_at_end=True,\n","    metric_for_best_model=metric_name,\n","    push_to_hub=False,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pk_OMZGiw9FC"},"outputs":[],"source":["metric = load_metric('f1')\n","def compute_metrics(eval_pred):\n","    predictions, labels = eval_pred\n","    predictions = np.argmax(predictions, axis=1)\n","    return metric.compute(predictions=predictions, references=labels, average='macro')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MtTDe5KLw9FD"},"outputs":[],"source":["trainer = Trainer(\n","    model,\n","    args,\n","    train_dataset=encoded_dataset_train,\n","    eval_dataset=encoded_dataset_dev,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":false,"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"Xgqamhzfw9FD","executionInfo":{"status":"ok","timestamp":1652658274333,"user_tz":240,"elapsed":437160,"user":{"displayName":"SYED NAWSHAD","userId":"11649352150405688224"}},"outputId":"45650dd5-b0e1-45ef-8390-63bdfe5d88e0"},"outputs":[{"output_type":"stream","name":"stderr","text":["The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__. If text, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 6851\n","  Num Epochs = 4\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 3428\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='3428' max='3428' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3428/3428 07:16, Epoch 4/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.479100</td>\n","      <td>0.480556</td>\n","      <td>0.812406</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.362800</td>\n","      <td>0.491711</td>\n","      <td>0.833988</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.310300</td>\n","      <td>0.524746</td>\n","      <td>0.832269</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.264800</td>\n","      <td>0.616285</td>\n","      <td>0.822081</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__. If text, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 762\n","  Batch size = 8\n","Saving model checkpoint to ./save_model/bert-base-uncased-finetuned-tweet/checkpoint-857\n","Configuration saved in ./save_model/bert-base-uncased-finetuned-tweet/checkpoint-857/config.json\n","Model weights saved in ./save_model/bert-base-uncased-finetuned-tweet/checkpoint-857/pytorch_model.bin\n","tokenizer config file saved in ./save_model/bert-base-uncased-finetuned-tweet/checkpoint-857/tokenizer_config.json\n","Special tokens file saved in ./save_model/bert-base-uncased-finetuned-tweet/checkpoint-857/special_tokens_map.json\n","The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__. If text, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 762\n","  Batch size = 8\n","Saving model checkpoint to ./save_model/bert-base-uncased-finetuned-tweet/checkpoint-1714\n","Configuration saved in ./save_model/bert-base-uncased-finetuned-tweet/checkpoint-1714/config.json\n","Model weights saved in ./save_model/bert-base-uncased-finetuned-tweet/checkpoint-1714/pytorch_model.bin\n","tokenizer config file saved in ./save_model/bert-base-uncased-finetuned-tweet/checkpoint-1714/tokenizer_config.json\n","Special tokens file saved in ./save_model/bert-base-uncased-finetuned-tweet/checkpoint-1714/special_tokens_map.json\n","The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__. If text, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 762\n","  Batch size = 8\n","Saving model checkpoint to ./save_model/bert-base-uncased-finetuned-tweet/checkpoint-2571\n","Configuration saved in ./save_model/bert-base-uncased-finetuned-tweet/checkpoint-2571/config.json\n","Model weights saved in ./save_model/bert-base-uncased-finetuned-tweet/checkpoint-2571/pytorch_model.bin\n","tokenizer config file saved in ./save_model/bert-base-uncased-finetuned-tweet/checkpoint-2571/tokenizer_config.json\n","Special tokens file saved in ./save_model/bert-base-uncased-finetuned-tweet/checkpoint-2571/special_tokens_map.json\n","The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__. If text, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 762\n","  Batch size = 8\n","Saving model checkpoint to ./save_model/bert-base-uncased-finetuned-tweet/checkpoint-3428\n","Configuration saved in ./save_model/bert-base-uncased-finetuned-tweet/checkpoint-3428/config.json\n","Model weights saved in ./save_model/bert-base-uncased-finetuned-tweet/checkpoint-3428/pytorch_model.bin\n","tokenizer config file saved in ./save_model/bert-base-uncased-finetuned-tweet/checkpoint-3428/tokenizer_config.json\n","Special tokens file saved in ./save_model/bert-base-uncased-finetuned-tweet/checkpoint-3428/special_tokens_map.json\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from ./save_model/bert-base-uncased-finetuned-tweet/checkpoint-1714 (score: 0.8339883748289776).\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=3428, training_loss=0.3453334421093294, metrics={'train_runtime': 437.0492, 'train_samples_per_second': 62.702, 'train_steps_per_second': 7.844, 'total_flos': 709032391428420.0, 'train_loss': 0.3453334421093294, 'epoch': 4.0})"]},"metadata":{},"execution_count":39}],"source":["trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"idnaCmp9w9FD","executionInfo":{"status":"ok","timestamp":1652658301298,"user_tz":240,"elapsed":26973,"user":{"displayName":"SYED NAWSHAD","userId":"11649352150405688224"}},"outputId":"7047cf2c-3f57-43ec-fd51-a832c7795d30"},"outputs":[{"output_type":"stream","name":"stderr","text":["The following columns in the test set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Prediction *****\n","  Num examples = 7613\n","  Batch size = 8\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='952' max='952' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [952/952 00:26]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all\t1\n","Forest fire near La Ronge Sask. Canada\t1\n","All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected\t1\n","13,000 people receive #wildfires evacuation orders in California \t1\n","Just got sent this photo from Ruby #Alaska as smoke from #wildfires pours into a school \t1\n","#RockyFire Update => California Hwy. 20 closed in both directions due to Lake County fire - #CAfire #wildfires\t1\n","#flood #disaster Heavy rain causes flash flooding of streets in Manitou, Colorado Springs areas\t1\n","I'm on top of the hill and I can see a fire in the woods...\t1\n","There's an emergency evacuation happening now in the building across the street\t1\n","I'm afraid that the tornado is coming to our area...\t1\n","Three people died from the heat wave so far\t1\n","Haha South Tampa is getting flooded hah- WAIT A SECOND I LIVE IN SOUTH TAMPA WHAT AM I GONNA DO WHAT AM I GONNA DO FVCK #flooding\t1\n","#raining #flooding #Florida #TampaBay #Tampa 18 or 19 days. I've lost count \t1\n","#Flood in Bago Myanmar #We arrived Bago\t1\n","Damage to school bus on 80 in multi car crash #BREAKING \t1\n","What's up man?\t0\n","I love fruits\t0\n","Summer is lovely\t0\n","My car is so fast\t0\n","What a goooooooaaaaaal!!!!!!\t0\n","this is ridiculous....\t0\n","London is cool ;)\t0\n","Love skiing\t0\n","What a wonderful day!\t0\n","LOOOOOOL\t0\n","No way...I can't eat that shit\t0\n","Was in NYC last week!\t0\n","Love my girlfriend\t0\n","Cooool :)\t0\n","Do you like pasta?\t0\n","The end!\t0\n","@bbcmtd Wholesale Markets ablaze http://t.co/lHYXEOHY6C\t1\n","We always try to bring the heavy. #metal #RT http://t.co/YAo1e0xngw\t0\n","#AFRICANBAZE: Breaking news:Nigeria flag set ablaze in Aba. http://t.co/2nndBGwyEi\t1\n","Crying out for more! Set me ablaze\t0\n","On plus side LOOK AT THE SKY LAST NIGHT IT WAS ABLAZE http://t.co/qqsmshaJ3N\t0\n","@PhDSquares #mufc they've built so much hype around new acquisitions but I doubt they will set the EPL ablaze this season.\t0\n","INEC Office in Abia Set Ablaze - http://t.co/3ImaomknnA\t1\n","Barbados #Bridgetown JAMAICA ÛÒ Two cars set ablaze: SANTA CRUZ ÛÓ Head of the St Elizabeth Police Superintende...  http://t.co/wDUEaj8Q4J\t1\n","Ablaze for you Lord :D\t0\n","Check these out: http://t.co/rOI2NSmEJJ http://t.co/3Tj8ZjiN21 http://t.co/YDUiXEfIpE http://t.co/LxTjc87KLS #nsfw\t0\n","on the outside you're ablaze and alive\n","but you're dead inside\t0\n","Had an awesome time visiting the CFC head office the ancop site and ablaze. Thanks to Tita Vida for taking care of us ??\t0\n","SOOOO PUMPED FOR ABLAZE ???? @southridgelife\t0\n","I wanted to set Chicago ablaze with my preaching... But not my hotel! http://t.co/o9qknbfOFX\t0\n","I gained 3 followers in the last week. You? Know your stats and grow with http://t.co/TIyUliF5c6\t0\n","How the West was burned: Thousands of wildfires ablaze in California alone http://t.co/vl5TBR3wbr\t1\n","Building the perfect tracklist to life leave the streets ablaze\t0\n","Check these out: http://t.co/rOI2NSmEJJ http://t.co/3Tj8ZjiN21 http://t.co/YDUiXEfIpE http://t.co/LxTjc87KLS #nsfw\t0\n","First night with retainers in. It's quite weird. Better get used to it; I have to wear them every single night for the next year at least.\t0\n","Deputies: Man shot before Brighton home set ablaze http://t.co/gWNRhMSO8k\t1\n","Man wife get six years jail for setting ablaze niece\n","http://t.co/eV1ahOUCZA\t1\n","SANTA CRUZ ÛÓ Head of the St Elizabeth Police Superintendent Lanford Salmon has r ... - http://t.co/vplR5Hka2u http://t.co/SxHW2TNNLf\t0\n","Police: Arsonist Deliberately Set Black Church In North CarolinaåÊAblaze http://t.co/pcXarbH9An\t1\n","Noches El-Bestia '@Alexis_Sanchez: happy to see my teammates and training hard ?? goodnight gunners.?????? http://t.co/uc4j4jHvGR'\t0\n","#Kurds trampling on Turkmen flag later set it ablaze while others vandalized offices of Turkmen Front in #Diyala http://t.co/4IzFdYC3cg\t1\n","TRUCK ABLAZE : R21. VOORTREKKER AVE. OUTSIDE OR TAMBO INTL. CARGO SECTION. http://t.co/8kscqKfKkF\t1\n","Set our hearts ablaze and every city was a gift And every skyline was like a kiss upon the lips @Û_ https://t.co/cYoMPZ1A0Z\t0\n","They sky was ablaze tonight in Los Angeles. I'm expecting IG and FB to be filled with sunset shots if I know my peeps!!\t0\n","How the West was burned: Thousands of wildfires ablaze in #California alone http://t.co/iCSjGZ9tE1 #climate #energy http://t.co/9FxmN0l0Bd\t1\n","Revel in yours wmv videos by means of mac farewell ablaze wmv en route to dvd: GtxRWm\t0\n","Progressive greetings!\n","\n","In about a month students would have set their pens ablaze in The Torch Publications'... http://t.co/9FxPiXQuJt\t0\n","Rene Ablaze &amp; Jacinta - Secret 2k13 (Fallen Skies Edit) - Mar 30 2013  https://t.co/7MLMsUzV1Z\t0\n","@Navista7 Steve these fires out here are something else! California is a tinderbox - and this clown was setting my 'hood ablaze @News24680\t1\n","#NowPlaying: Rene Ablaze &amp; Ian Buff - Magnitude http://t.co/Av2JSjfFtc  #EDM\t0\n","@nxwestmidlands huge fire at Wholesale markets ablaze http://t.co/rwzbFVNXER\t1\n","@ablaze what time does your talk go until? I don't know if I can make it due to work.\t0\n","'I can't have kids cuz I got in a bicycle accident &amp; split my testicles. it's impossible for me to have kids' MICHAEL YOU ARE THE FATHER\t0\n","Accident on I-24 W #NashvilleTraffic. Traffic moving 8m slower than usual. https://t.co/0GHk693EgJ\t1\n","Accident center lane blocked in #SantaClara on US-101 NB before Great America Pkwy #BayArea #Traffic http://t.co/pmlOhZuRWR\t1\n","http://t.co/GKYe6gjTk5 Had a #personalinjury accident this summer? Read our advice &amp; see how a #solicitor can help #OtleyHour\t1\n","#stlouis #caraccidentlawyer Speeding Among Top Causes of Teen Accidents https://t.co/k4zoMOF319 https://t.co/S2kXVM0cBA Car Accident teeÛ_\t1\n","Reported motor vehicle accident in Curry on Herman Rd near Stephenson involving an overturned vehicle. Please use... http://t.co/YbJezKuRW1\t1\n","BigRigRadio Live Accident Awareness\t1\n","I-77 Mile Marker 31 South Mooresville  Iredell Vehicle Accident Ramp Closed at 8/6 1:18 PM\t1\n","RT @SleepJunkies: Sleeping pills double your risk of a car accident http://t.co/7s9Nm1fiCT\t0\n","'By accident' they knew what was gon happen https://t.co/Ysxun5vCeh\t0\n","Traffic accident N CABRILLO HWY/MAGELLAN AV MIR (08/06/15 11:03:58)\t1\n","I-77 Mile Marker 31 to 40 South Mooresville  Iredell Vehicle Accident Congestion at 8/6 1:18 PM\t1\n","the pastor was not in the scene of the accident......who was the owner of the range rover ?\t1\n","mom: 'we didn't get home as fast as we wished' \n","me: 'why is that?'\n","mom: 'there was an accident and some truck spilt mayonnaise all over ??????\t0\n","I was in a horrible car accident this past Sunday. I'm finally able to get around. Thank you GOD??\t1\n","Can wait to see how pissed Donnie is when I tell him I was in ANOTHER accident??\t0\n","#TruckCrash Overturns On #FortWorth Interstate http://t.co/Rs22LJ4qFp Click here if you've been in a crash&gt;http://t.co/Ld0unIYw4k\t1\n","Accident in #Ashville on US 23 SB before SR 752 #traffic http://t.co/hylMo0WgFI\t1\n","Carolina accident: Motorcyclist Dies in I-540 Crash With Car That Crossed Median: A motorcycle rider traveling... http://t.co/p18lzRlmy6\t1\n","FYI CAD:FYI: ;ACCIDENT PROPERTY DAMAGE;NHS;999 PINER RD/HORNDALE DR\t1\n","RT nAAYf: First accident in years. Turning onto Chandanee Magu from near MMA. Taxi rammed into me while I was halfway turned. Everyone confÛ_\t1\n","Accident left lane blocked in #Manchester on Rt 293 NB before Eddy Rd stop and go traffic back to NH-3A delay of 4 mins #traffic\t1\n",";ACCIDENT PROPERTY DAMAGE; PINER RD/HORNDALE DR\t1\n","???? it was an accident http://t.co/Oia5fxi4gM\t1\n","FYI CAD:FYI: ;ACCIDENT PROPERTY DAMAGE;WPD;1600 S 17TH ST\t1\n","8/6/2015@2:09 PM: TRAFFIC ACCIDENT NO INJURY at 2781 WILLIS FOREMAN RD http://t.co/VCkIT6EDEv\t1\n","Aashiqui Actress Anu Aggarwal On Her Near-Fatal Accident http://t.co/6Otfp31LqW\t1\n","Suffield Alberta Accident https://t.co/bPTmlF4P10\t1\n","9 Mile backup on I-77 South...accident blocking the Right 2 Lanes at Exit 31 Langtree Rd...consider NC 115 or NC 150 to NC 16 as alternate\t1\n","Has an accident changed your life? We will help you determine options that can financially support life care plans and on-going treatment.\t0\n","#BREAKING: there was a deadly motorcycle car accident that happened to #Hagerstown today. I'll have more details at 5 @Your4State. #WHAG\t1\n","@flowri were you marinading it or was it an accident?\t0\n","only had a car for not even a week and got in a fucking car accident .. Mfs can't fucking drive .\t1\n"]}],"source":["#get_test_predictions\n","predictions = trainer.predict(encoded_dataset_test)\n","preds = np.argmax(predictions.predictions, axis=-1)\n","#print the top 100 examples\n","for i in range(100):\n","    print(encoded_dataset_test['text'][i], preds[i], sep='\\t')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y3Q4TtBCw9FE"},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{"id":"nroShEXUw9FE"},"source":["### Optional: custom class weight"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aH5yPpDKw9FF","executionInfo":{"status":"ok","timestamp":1652658301299,"user_tz":240,"elapsed":15,"user":{"displayName":"SYED NAWSHAD","userId":"11649352150405688224"}},"outputId":"49e76cc9-6ea4-4fd2-ebf6-e0f428c2aa2b"},"outputs":[{"output_type":"stream","name":"stdout","text":["[3907 2944]\n","[0.87675966 1.16355299]\n"]}],"source":["train_labels = encoded_dataset_train['label']\n","print(np.bincount(train_labels))\n","class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(train_labels), y=list(train_labels))\n","print(class_weights)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YqI7263Uw9FG"},"outputs":[],"source":["class CustomTrainer(Trainer):\n","    def compute_loss(self, model, inputs, return_outputs=False):\n","        #print(inputs)\n","        labels = inputs.get(\"labels\")\n","        # forward pass\n","        outputs = model(**inputs)\n","        logits = outputs.get(\"logits\")\n","        # compute custom loss (suppose one has 2 labels with different weights)\n","        loss_fct = nn.CrossEntropyLoss(weight=torch.Tensor(class_weights).to('cuda'))\n","        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n","        return (loss, outputs) if return_outputs else loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BzbCK8nJw9FG"},"outputs":[],"source":["trainer = CustomTrainer(\n","    model,\n","    args,\n","    train_dataset=encoded_dataset_train,\n","    eval_dataset=encoded_dataset_dev,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":false,"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"KjavAkK_w9FG","executionInfo":{"status":"ok","timestamp":1652658737303,"user_tz":240,"elapsed":435843,"user":{"displayName":"SYED NAWSHAD","userId":"11649352150405688224"}},"outputId":"1ac151ea-1816-4680-8831-2a7fc95b6638"},"outputs":[{"output_type":"stream","name":"stderr","text":["The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__. If text, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 6851\n","  Num Epochs = 4\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 3428\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='3428' max='3428' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3428/3428 07:15, Epoch 4/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.288600</td>\n","      <td>0.796119</td>\n","      <td>0.801569</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.231500</td>\n","      <td>0.823685</td>\n","      <td>0.825813</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.213400</td>\n","      <td>0.759240</td>\n","      <td>0.826763</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.166900</td>\n","      <td>0.910270</td>\n","      <td>0.812283</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__. If text, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 762\n","  Batch size = 8\n","Saving model checkpoint to ./save_model/bert-base-uncased-finetuned-tweet/checkpoint-857\n","Configuration saved in ./save_model/bert-base-uncased-finetuned-tweet/checkpoint-857/config.json\n","Model weights saved in ./save_model/bert-base-uncased-finetuned-tweet/checkpoint-857/pytorch_model.bin\n","tokenizer config file saved in ./save_model/bert-base-uncased-finetuned-tweet/checkpoint-857/tokenizer_config.json\n","Special tokens file saved in ./save_model/bert-base-uncased-finetuned-tweet/checkpoint-857/special_tokens_map.json\n","The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__. If text, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 762\n","  Batch size = 8\n","Saving model checkpoint to ./save_model/bert-base-uncased-finetuned-tweet/checkpoint-1714\n","Configuration saved in ./save_model/bert-base-uncased-finetuned-tweet/checkpoint-1714/config.json\n","Model weights saved in ./save_model/bert-base-uncased-finetuned-tweet/checkpoint-1714/pytorch_model.bin\n","tokenizer config file saved in ./save_model/bert-base-uncased-finetuned-tweet/checkpoint-1714/tokenizer_config.json\n","Special tokens file saved in ./save_model/bert-base-uncased-finetuned-tweet/checkpoint-1714/special_tokens_map.json\n","The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__. If text, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 762\n","  Batch size = 8\n","Saving model checkpoint to ./save_model/bert-base-uncased-finetuned-tweet/checkpoint-2571\n","Configuration saved in ./save_model/bert-base-uncased-finetuned-tweet/checkpoint-2571/config.json\n","Model weights saved in ./save_model/bert-base-uncased-finetuned-tweet/checkpoint-2571/pytorch_model.bin\n","tokenizer config file saved in ./save_model/bert-base-uncased-finetuned-tweet/checkpoint-2571/tokenizer_config.json\n","Special tokens file saved in ./save_model/bert-base-uncased-finetuned-tweet/checkpoint-2571/special_tokens_map.json\n","The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, __index_level_0__. If text, __index_level_0__ are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 762\n","  Batch size = 8\n","Saving model checkpoint to ./save_model/bert-base-uncased-finetuned-tweet/checkpoint-3428\n","Configuration saved in ./save_model/bert-base-uncased-finetuned-tweet/checkpoint-3428/config.json\n","Model weights saved in ./save_model/bert-base-uncased-finetuned-tweet/checkpoint-3428/pytorch_model.bin\n","tokenizer config file saved in ./save_model/bert-base-uncased-finetuned-tweet/checkpoint-3428/tokenizer_config.json\n","Special tokens file saved in ./save_model/bert-base-uncased-finetuned-tweet/checkpoint-3428/special_tokens_map.json\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from ./save_model/bert-base-uncased-finetuned-tweet/checkpoint-2571 (score: 0.8267629388511841).\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=3428, training_loss=0.2242263940835639, metrics={'train_runtime': 435.6999, 'train_samples_per_second': 62.897, 'train_steps_per_second': 7.868, 'total_flos': 709032391428420.0, 'train_loss': 0.2242263940835639, 'epoch': 4.0})"]},"metadata":{},"execution_count":44}],"source":["trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6dGho0ckw9FG"},"outputs":[],"source":[""]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.10"},"colab":{"name":"Base_BERT_Disaster_Tweets.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"1a3a7468d9f04a9e82a6f186d7d0d58b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3a222dc384b8448ca27c005bd8f99885","IPY_MODEL_9387fb917e2d4feab271f00a6ff26f84","IPY_MODEL_7dd8d34f006c480cb2f5eb199a6b3c7c"],"layout":"IPY_MODEL_459542131e09425ea904822aa676a24d"}},"3a222dc384b8448ca27c005bd8f99885":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7e16e4956e524cad8e16c2c0131d91bd","placeholder":"​","style":"IPY_MODEL_9af89e4f8bb1483e88952aec7a15522c","value":"100%"}},"9387fb917e2d4feab271f00a6ff26f84":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d3383134371c491b85f99c3c740b3485","max":7,"min":0,"orientation":"horizontal","style":"IPY_MODEL_07d139fad4d342ed8e34ef48ff832784","value":7}},"7dd8d34f006c480cb2f5eb199a6b3c7c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_deef14893fcc47ef9d77772de4c9e687","placeholder":"​","style":"IPY_MODEL_69730dde435840f1af4edee14e309cfa","value":" 7/7 [00:10&lt;00:00,  1.64s/ba]"}},"459542131e09425ea904822aa676a24d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e16e4956e524cad8e16c2c0131d91bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9af89e4f8bb1483e88952aec7a15522c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d3383134371c491b85f99c3c740b3485":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"07d139fad4d342ed8e34ef48ff832784":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"deef14893fcc47ef9d77772de4c9e687":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"69730dde435840f1af4edee14e309cfa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"681d960626c04e9a8bd5e994ed44e983":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dae9098bd2e6428987b136b3d7065d9d","IPY_MODEL_c8247213072b4ed0854285a538c40633","IPY_MODEL_dde67639c1c4476da066996a1e4c7d34"],"layout":"IPY_MODEL_1ac02a881d5947ca942aa1156b3f907c"}},"dae9098bd2e6428987b136b3d7065d9d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8ccc25e972c34e90b5e5e6d63a20048e","placeholder":"​","style":"IPY_MODEL_5d2b4aa2cc69481887f2b12a0dfd8c76","value":"100%"}},"c8247213072b4ed0854285a538c40633":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f08a4b01eac44999a0fb3ef40bea4982","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_52fd5a1be15d4af79945c1ca21746e02","value":1}},"dde67639c1c4476da066996a1e4c7d34":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_14252d3e485446a288b5f76943c45765","placeholder":"​","style":"IPY_MODEL_e28340c964a6489f8889f54d924d9fe4","value":" 1/1 [00:01&lt;00:00,  1.18s/ba]"}},"1ac02a881d5947ca942aa1156b3f907c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8ccc25e972c34e90b5e5e6d63a20048e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d2b4aa2cc69481887f2b12a0dfd8c76":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f08a4b01eac44999a0fb3ef40bea4982":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"52fd5a1be15d4af79945c1ca21746e02":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"14252d3e485446a288b5f76943c45765":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e28340c964a6489f8889f54d924d9fe4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"45d96734b8f94c8eacaad0fbfac5851b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_07a7259ac87c4d44905926c2846fb8c6","IPY_MODEL_3a2d94b24a0e40aa8cdf5c69c852d7bd","IPY_MODEL_6beebd44d1924e659b5a3258030715a2"],"layout":"IPY_MODEL_b9a3a7bd2b734ff4b6dfc631eb1a2f00"}},"07a7259ac87c4d44905926c2846fb8c6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_23c3345255e740d6a3f3d8ca3bcbc5e6","placeholder":"​","style":"IPY_MODEL_95cb2825257d43b9a912c99288a2e4e9","value":"100%"}},"3a2d94b24a0e40aa8cdf5c69c852d7bd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_faf7316f012a4ca981ab3bb4a026c03a","max":8,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f8ca15121cea41a2917e236b1da9b597","value":8}},"6beebd44d1924e659b5a3258030715a2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5bd09b60d88a4e2bba9c4c0f03ffd4eb","placeholder":"​","style":"IPY_MODEL_09758a28cab34b9786de78b888b080e7","value":" 8/8 [00:04&lt;00:00,  1.93ba/s]"}},"b9a3a7bd2b734ff4b6dfc631eb1a2f00":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"23c3345255e740d6a3f3d8ca3bcbc5e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"95cb2825257d43b9a912c99288a2e4e9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"faf7316f012a4ca981ab3bb4a026c03a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f8ca15121cea41a2917e236b1da9b597":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5bd09b60d88a4e2bba9c4c0f03ffd4eb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"09758a28cab34b9786de78b888b080e7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}